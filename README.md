# Paper Collection of Hierarchical Reinforcement Learning

This is a collection of research and review papers of hierarchicial reinforcement learning (HRL). Several multi-goal reinforcement learning research papers are also listed here due to high correlation. All the papers are sorted by time. **Any suggestions and pull requests are more than welcome**.

The sharing principle of these references here is for research. If any authors do not want their paper to be listed here, please feel free to contact [Jiarui Jin](http://Jinjiarui.github.io/) (Email: jinjiarui97 [AT] gmail.com).



## Review Papers

* [Temporal abstraction in reinforcement learning](https://dl.acm.org/citation.cfm?id=932003) by Doina Precup, 	Richard S. Sutton, University of Massachusetts Amherst, 2000.
* [Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning](https://www.sciencedirect.com/science/article/pii/S0004370299000521) by Richard S. Sutton, Doina Precup, Satinder Singh, Artificial Intelligence, 1999.
* [Recent Advances in Hierarchical Reinforcement Learning](https://people.cs.umass.edu/~mahadeva/papers/hrl.pdf) by Andrew G. Barto, Sridhar Mahadevan, Discrete Event Dynamic Systems: Theory and Applications, 1999.


## Research Papers

### Feudal Learning
* [Directed-Info GAIL:Learning Hierarchical Policies from Unsegmented Demonstrationsusing Directed Information](https://arxiv.org/pdf/1810.01266.pdf) by Arjun Sharma, Mohit Sharma, Nicholas Rhinehart, Kris M. Kitani. ICLR, 2019.
* [Data-Efficient Hierarchical Reinforcement Learning](https://arxiv.org/abs/1805.08296) by Ofir Nachum, Shixiang Gu, Honglak Lee, Sergey Levine. NeurIPS, 2018.
* [Hierarchical Imitation and Reinforcement Learning](https://arxiv.org/pdf/1803.00590.pdf) by Hoang M. Le, Nan Jiang, Alekh Agarwal, Miroslav Dudík, Yisong Yue, Hal Daumé III. ICML, 2018.
* [Meta Learning Shared Hierarchies](https://arxiv.org/pdf/1710.09767.pdf) by Kevin Frans, Jonathan Ho, Xi Chen, Pieter Abbeel, John Schulman. ICLR, 2018.
* [Federated Control with Hierarchical Multi-Agent Deep Reinforcement Learning](https://arxiv.org/pdf/1712.08266.pdf) by Saurabh Kumar, Pararth Shah, Dilek Hakkani-Tür, Larry Heck. NeurIPS Workshop, 2017.
* [FeUdal Networks for Hierarchical Reinforcement Learning](https://arxiv.org/abs/1703.01161) by Alexander Sasha Vezhnevets, Simon Osindero, Tom Schaul, Nicolas Heess, Max Jaderberg, David Silver, Koray Kavukcuoglu. ICML, 2017.


### Options Framework
* [The Option-Critic Architecture](http://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14858/14328) by Pierre-Luc Bacon, Jean Harb, Doina Precup. AAAI, 2017.
* [Combining intrinsic motivation and hierarchical reinforcement learning](https://drive.google.com/file/d/1zjc6q0i2J4JoJ8fnVnQslPRoiiQku3Gl/view) by
Maria K. Eckstein, Anne GE Collins. NeurIPS Workshop, 2017.
* [Importance Sampled Option-Critic for More Sample Efficient Reinforcement Learning](https://drive.google.com/file/d/1wTdOEFW22w-ZXTyTSWw_fhfIZcX4Y2Yn/view) by
Karan Goel, Emma Brunskill. NeurIPS Workshop, 2017.
* [Optimal Hierarchical Policy Extraction From Noisy Imperfect Demonstrations](https://drive.google.com/file/d/101FsZkczKMfGeUBTP-089mhkTeepj8IW/view) by Karan Goel, Tong Mu, Emma Brunskil. NeurIPS Workshop, 2017.
* [When waiting is not an option: Learning options with a deliberation cost](https://arxiv.org/pdf/1709.04571.pdf) by Jean Harb, Pierre-Luc Bacon, Martin Klissarov, Doina Precup. arXiv, 2017.
* [Toward Good Abstractions for Lifelong Learning](https://drive.google.com/file/d/1MrNzgpVXYRlp8xfQ6Qjmxs7UNO5T376g/view) by David Abel, Dilip Arumugam, Lucas Lehnert, Michael Littman. NeurIPS Workshop, 2017.
* [Landmark Options Via Reflection (LOVR) in Multi-task Lifelong Reinforcement Learning](https://drive.google.com/file/d/1o-18oSWhxJ73kOXQkfgR2tBvkOD8DJrq/view) by
 Nicholas Denis, Maia Fraser. NeurIPS Workshop, 2017.
* [Learning with Options that Terminate Off-Policy](https://drive.google.com/file/d/16kUKs4LMAc1QsueV0HXQAAKIcVlItvob/view) by Anna Harutyunyan, Peter Vrancx, Pierre-Luc Bacon, Doina Precup, Ann Nowe. NeurIPS Workshop, 2017.
* [Universal Option Models](http://papers.nips.cc/paper/5590-universal-option-models) by Hengshuai Yao, Csaba Szepesvari, Rich Sutton, Joseph Modayil. NeurIPS, 2014.


### Value Function
* [CURIOUS: Intrinsically Motivated Modular
Multi-Goal Reinforcement Learning](http://proceedings.mlr.press/v97/colas19a/colas19a.pdf) by Cedric Colas, Pierre Fournier, Olivier Sigaud, Mohamed Chetouani, Pierre-Yves Oudeyer. ICML, 2019.
* [Learning Multi-level Hierarchies with Hindsight](https://openreview.net/pdf?id=ryzECoAcY7) by Andrew Levy, Andrew Levy, Robert Platt, Kate Saenko. ICLR, 2019.
* [A Demon Control Architecture with Off-Policy Learning and Flexible Behavior Policy](https://drive.google.com/file/d/1tV1Lw1fIsQTihSzSvBT206XX2_6UjiRB/view) by
Shangtong Zhang, Richard Sutton. NeurIPS Workshop, 2017.
* [Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation](http://papers.nips.cc/paper/6233-hierarchical-deep-reinforcement-learning-integrating-temporal-abstraction-and-intrinsic-motivation.pdf) by Tejas D. Kullkarni, Karthik R. Narasimhan, Ardavan Saeedi and Joshua B. Tenenbaum. NeurIPS, 2016.
* [Universal Value Function Approximators](http://proceedings.mlr.press/v37/schaul15.pdf) by Tom Schaul, Dan Horgan, Karol Gregor, David Silver. ICML, 2015.
* [Hierarchical Reinforcement Learning with the Maxq Value Function Decomposition](https://www.jair.org/index.php/jair/article/view/10266) by Thomas G Dietterich. Journal of Artificial Intelligence Research, 2000.



### Representaion Learning
* [Near-Optimal Representation Learning for Hierarchical Reinforcement Learning](https://openreview.net/pdf?id=H1emus0qF7) by Ofir Nachum, Shixiang Gu, Honglak Lee, Sergey Levine. ICLR, 2019.
* [Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization](https://openreview.net/pdf?id=Hyl_vjC5KQ) by Takayuki Osa, Voot Tangkaratt, Masashi Sugiyama. ICLR, 2019.
* [Self-Consistent Trajectory Autoencoder: Hierarchical Reinforcement Learning
with Trajectory Embeddings](https://arxiv.org/pdf/1806.02813.pdf) by John D. Co-Reyes, YuXuan Liu, Abhishek Gupta, Benjamin Eysenbach, Pieter Abbeel, Sergey Levine. ICML, 2018.

## Entropy-based
* [Maximum Entropy-Regularized Multi-Goal Reinforcement Learning](https://arxiv.org/pdf/1905.08786.pdf) by Rui Zhao, Xudong Sun, Volker Tresp. ICML, 2019.
* [Hierarchical RL Using an Ensemble of Proprioceptive Periodic Policies](https://openreview.net/pdf?id=SJz1x20cFQ) by Kenneth Marino, Abhinav Gupta, Rob Fergus, Arthur Szlam. ICLR, 2019.
* [Latent Space Policies for Hierarchical Reinforcement Learning](https://arxiv.org/pdf/1804.02808.pdf) by Tuomas Haarnoja, Kristian Hartikainen, Pieter Abbee, Sergey Levine. ICML, 2018.


## Application Papers
* [Recommender System] [Hierarchical Reinforcement Learning for Course Recommendation in MOOCs](https://xiaojingzi.github.io/publications/AAAI19-zhang-et-al-HRL.pdf) by Jing Zhang, Bowen Hao, Bo Chen, Cuiping Li, Hong Chen, Jimeng Sun. AAAI, 2019.
* [Communication] [Feudal Multi-Agent Hierarchies for Cooperative Reinforcement Learning](https://arxiv.org/pdf/1901.08492.pdf) by Sanjeevan Ahilan, Peter Dayan. arXiv, 2019.
* [Ride-hailing] [CoRide: Joint Order Dispatching and Fleet Management for Multi-Scale Ride-Hailing Platforms](https://arxiv.org/pdf/1905.11353.pdf) by Jiarui Jin, Ming Zhou, Weinan Zhang, Minne Li, Zilong Guo, Zhiwei Qin, Yan Jiao, Xiaocheng Tang, Chenxi Wang, Jun Wang, Guobin Wu, Jieping Ye. arXiv, 2019.
* [Robot] [Learning by Playing – Solving Sparse Reward Tasks from Scratch](https://arxiv.org/abs/1802.10567) by Martin Riedmiller, Roland Hafner, Thomas Lampe, Michael Neunert, Jonas Degrave, Tom Van de Wiele, Volodymyr Mnih, Nicolas Heess, Tobias Springenberg. ICML, 2018.
* [Multi-task] [Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning](https://openreview.net/pdf?id=SJJQVZW0b) by Tianmin Shu, Caiming Xiong, Richard Socher. ICLR, 2018.
* [Subtask] [Hierarchical Reinforcement Learning for Zero-shot Generalization with Subtask Dependencies](https://arxiv.org/pdf/1807.07665.pdf) by Sungryull Sohn, Junhyuk Oh, Honglak Lee. NeurIPS, 2018.
* [Text Generation] [Long Text Generation via Adversarial Training with Leaked Information](https://arxiv.org/pdf/1709.08624.pdf) by Jiaxian Guo, Sidi Lu, Han Cai, Weinan Zhang, Yong Yu, Jun Wang. AAAI, 2018.
